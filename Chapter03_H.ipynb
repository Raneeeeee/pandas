{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418050b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 페이스북, 애플 , 아마존, 넷플릭스, 구글 주식의 데이터를 보고 싶지만 각각  별도의 CSV파일만 있다. \n",
    "#이 파일들을 하나의 파일로 결합하고  FAANG 데이터를 이후 연습문제에 사용할 수 있도록 fang DataFrame으로 저장한다 \n",
    "\n",
    "import pandas as pd\n",
    "# a)\n",
    "df_am= pd.read_csv(\"data/amzn.csv\")\n",
    "df_fb= pd.read_csv(\"data/fb.csv\")\n",
    "df_ap = pd.read_csv(\"data/aapl.csv\")\n",
    "df_go = pd.read_csv(\"data/goog.csv\")\n",
    "df_nf = pd.read_csv(\"data/nflx.csv\")\n",
    "#b) \n",
    "df_nf['ticker'] = 'nflx'\n",
    "df_am['ticker'] = 'amzn'\n",
    "df_ap['ticker'] = 'aapl'\n",
    "df_fb['ticker'] = 'fb'\n",
    "df_go['ticker'] = 'goog'\n",
    "#c)\n",
    "f_df = pd.concat([df_nf,df_am,df_ap,df_fb,df_go])\n",
    "\n",
    "#d)\n",
    "#f_df.to_csv(\"data/FAANG.CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f631fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0             int64\n",
      "date          datetime64[ns]\n",
      "high                 float64\n",
      "low                  float64\n",
      "open                 float64\n",
      "close                float64\n",
      "volume                 int32\n",
      "ticker                object\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "      Unnamed: 0       date         high          low         open  \\\n",
      "502            0 2018-01-02    43.075001    42.314999    42.540001   \n",
      "251            0 2018-01-02  1190.000000  1170.510010  1172.000000   \n",
      "753            0 2018-01-02   181.580002   177.550003   177.679993   \n",
      "1004           0 2018-01-02  1066.939941  1045.229980  1048.339966   \n",
      "0              0 2018-01-02   201.649994   195.419998   196.100006   \n",
      "...          ...        ...          ...          ...          ...   \n",
      "752          250 2018-12-31    39.840000    39.119999    39.632500   \n",
      "501          250 2018-12-31  1520.760010  1487.000000  1510.800049   \n",
      "1003         250 2018-12-31   134.639999   129.949997   134.449997   \n",
      "1254         250 2018-12-31  1052.699951  1023.590027  1050.959961   \n",
      "250          250 2018-12-31   270.100006   260.000000   260.160004   \n",
      "\n",
      "            close     volume ticker  \n",
      "502     43.064999  102223600   aapl  \n",
      "251   1189.010010    2694500   amzn  \n",
      "753    181.419998   18151900     fb  \n",
      "1004  1065.000000    1237600   goog  \n",
      "0      201.070007   10966900   nflx  \n",
      "...           ...        ...    ...  \n",
      "752     39.435001  140014000   aapl  \n",
      "501   1501.969971    6954500   amzn  \n",
      "1003   131.089996   24625300     fb  \n",
      "1254  1035.609985    1493300   goog  \n",
      "250    267.660004   13508900   nflx  \n",
      "\n",
      "[1255 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#2 . faang에서 유형 변환을 사용해 date 열의 값을 datetimes 형식으로, volume 열의 값 을 정수형으로 변환한다. \n",
    "#그런 다음 date와 ticker를 기준으로 정렬한다.\n",
    "\n",
    "df= pd.read_csv(\"data/FAANG.csv\")\n",
    "\n",
    "df['date'] =  pd.to_datetime(df['date'])\n",
    "df['volume'] =  df['volume'].astype(\"int\")\n",
    "print(df.dtypes)\n",
    "print(type(df['date']))\n",
    "\n",
    "#정렬 \n",
    "df_dsort= df.sort_values(by=['date', 'ticker'] ,ascending=True)\n",
    "print(df_dsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e34e0331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0       date         high          low         open  \\\n",
      "1130         126 2018-07-03  1135.819946  1100.020020  1135.819946   \n",
      "1230         226 2018-11-23  1037.589966  1022.398987  1030.000000   \n",
      "1103          99 2018-05-24  1080.469971  1066.150024  1079.000000   \n",
      "1134         130 2018-07-10  1159.589966  1149.589966  1156.979980   \n",
      "1156         152 2018-08-09  1255.541992  1246.010010  1249.900024   \n",
      "1163         159 2018-08-20  1211.000000  1194.625977  1205.020020   \n",
      "1165         161 2018-08-22  1211.839966  1199.000000  1200.000000   \n",
      "\n",
      "            close  volume ticker  value_min  \n",
      "1130  1102.890015  679000   goog        1.0  \n",
      "1230  1023.880005  691500   goog        2.0  \n",
      "1103  1079.239990  766800   goog        3.0  \n",
      "1134  1152.839966  798400   goog        4.0  \n",
      "1156  1249.099976  848600   goog        5.0  \n",
      "1163  1207.770020  870800   goog        6.0  \n",
      "1165  1207.329956  887400   goog        7.0  \n"
     ]
    }
   ],
   "source": [
    "# 3. fang의 value열에서 가장 낮은 값 7개를 찾는다.\n",
    "df_v= df.sort_values(by=['volume'],ascending=True)\n",
    "print(df_v[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd1a8c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>42.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amzn</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>177.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goog</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1048.339966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>196.100006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date variable        value\n",
       "0   aapl 2018-01-02     open    42.540001\n",
       "1   amzn 2018-01-02     open  1172.000000\n",
       "2     fb 2018-01-02     open   177.679993\n",
       "3   goog 2018-01-02     open  1048.339966\n",
       "4   nflx 2018-01-02     open   196.100006"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 이제 데이터는 긴 형태와 넓은 형태의 중간에 있다. melt()를 사용해 완전히 긴 형태 로 바꾼다. \n",
    "# 힌트: date와 ticker는 ID 변수다(이 값들은 각 행을 고유하게 식별할 수 있다.\n",
    "# open, high, loy, close, volume 열이 분리되지 않도록 나머지 부분도 멜팅해야 한다.\n",
    "melted_faang = df.melt(\n",
    "    id_vars=['ticker', 'date'], \n",
    "    value_vars=['open', 'high', 'low', 'close', 'volume']\n",
    ")\n",
    "melted_faang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d58fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateRep                                                               object\n",
      "day                                                                    int64\n",
      "month                                                                  int64\n",
      "year                                                                   int64\n",
      "cases                                                                  int64\n",
      "deaths                                                                 int64\n",
      "countriesAndTerritories                                               object\n",
      "geoId                                                                 object\n",
      "countryterritoryCode                                                  object\n",
      "popData2019                                                          float64\n",
      "continentExp                                                          object\n",
      "Cumulative_number_for_14_days_of_COVID-19_cases_per_100000           float64\n",
      "date                                                          datetime64[ns]\n",
      "dtype: object\n",
      "          dateRep  day  month  year  cases  deaths countriesAndTerritories  \\\n",
      "10     01/01/2020    1      1  2020      0       0                   India   \n",
      "14     01/01/2020    1      1  2020      0       0                   China   \n",
      "21     01/01/2020    1      1  2020      0       0                  Mexico   \n",
      "27     01/01/2020    1      1  2020      0       0                     USA   \n",
      "29     01/01/2020    1      1  2020      0       0                   Spain   \n",
      "...           ...  ...    ...   ...    ...     ...                     ...   \n",
      "43384  18/09/2020   18      9  2020   3395      21                      UK   \n",
      "43411  18/09/2020   18      9  2020   7568     187                Colombia   \n",
      "43418  18/09/2020   18      9  2020  43567     831                     USA   \n",
      "43428  18/09/2020   18      9  2020   1583      13                   Italy   \n",
      "43434  18/09/2020   18      9  2020  14389      90                   Spain   \n",
      "\n",
      "      geoId countryterritoryCode   popData2019 continentExp  \\\n",
      "10       IN                  IND  1.366418e+09         Asia   \n",
      "14       CN                  CHN  1.433784e+09         Asia   \n",
      "21       MX                  MEX  1.275755e+08      America   \n",
      "27       US                  USA  3.290649e+08      America   \n",
      "29       ES                  ESP  4.693706e+07       Europe   \n",
      "...     ...                  ...           ...          ...   \n",
      "43384    UK                  GBR  6.664711e+07       Europe   \n",
      "43411    CO                  COL  5.033944e+07      America   \n",
      "43418    US                  USA  3.290649e+08      America   \n",
      "43428    IT                  ITA  6.035955e+07       Europe   \n",
      "43434    ES                  ESP  4.693706e+07       Europe   \n",
      "\n",
      "       Cumulative_number_for_14_days_of_COVID-19_cases_per_100000       date  \n",
      "10                                                   NaN          2020-01-01  \n",
      "14                                                   NaN          2020-01-01  \n",
      "21                                                   NaN          2020-01-01  \n",
      "27                                                   NaN          2020-01-01  \n",
      "29                                                   NaN          2020-01-01  \n",
      "...                                                  ...                 ...  \n",
      "43384                                          61.822634          2020-09-18  \n",
      "43411                                         203.361408          2020-09-18  \n",
      "43418                                         159.179230          2020-09-18  \n",
      "43428                                          33.321987          2020-09-18  \n",
      "43434                                         300.510940          2020-09-18  \n",
      "\n",
      "[3121 rows x 13 columns]\n",
      "countriesAndTerritories  Argentina   Brazil  China  Colombia    India   Italy  \\\n",
      "date                                                                            \n",
      "2020-01-01                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
      "2020-01-02                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
      "2020-01-03                     0.0      0.0   17.0       0.0      0.0     0.0   \n",
      "2020-01-04                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
      "2020-01-05                     0.0      0.0   15.0       0.0      0.0     0.0   \n",
      "...                            ...      ...    ...       ...      ...     ...   \n",
      "2020-09-14                 10778.0  14768.0   29.0    7355.0  92071.0  1456.0   \n",
      "2020-09-15                  9056.0  15155.0   22.0    5573.0  83809.0  1008.0   \n",
      "2020-09-16                  9908.0  36653.0   24.0    6698.0  90123.0  1229.0   \n",
      "2020-09-17                 11893.0  36820.0    7.0    7787.0  97894.0  1452.0   \n",
      "2020-09-18                 11674.0  36303.0   44.0    7568.0  96424.0  1583.0   \n",
      "\n",
      "countriesAndTerritories  Mexico    Peru  Russia    Spain  Turkey      UK  \\\n",
      "date                                                                       \n",
      "2020-01-01                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
      "2020-01-02                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
      "2020-01-03                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
      "2020-01-04                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
      "2020-01-05                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
      "...                         ...     ...     ...      ...     ...     ...   \n",
      "2020-09-14               4408.0  6787.0  5449.0  27404.0  1527.0  3330.0   \n",
      "2020-09-15               3335.0  4241.0  5509.0   9437.0  1716.0  2621.0   \n",
      "2020-09-16               4771.0  4160.0  5529.0  11193.0  1742.0  3103.0   \n",
      "2020-09-17               4444.0  6380.0  5670.0  11291.0  1771.0  3991.0   \n",
      "2020-09-18               3182.0  5698.0  5762.0  14389.0  1648.0  3395.0   \n",
      "\n",
      "countriesAndTerritories      USA  \n",
      "date                              \n",
      "2020-01-01                   0.0  \n",
      "2020-01-02                   0.0  \n",
      "2020-01-03                   0.0  \n",
      "2020-01-04                   0.0  \n",
      "2020-01-05                   0.0  \n",
      "...                          ...  \n",
      "2020-09-14               33871.0  \n",
      "2020-09-15               34841.0  \n",
      "2020-09-16               51473.0  \n",
      "2020-09-17               24598.0  \n",
      "2020-09-18               43567.0  \n",
      "\n",
      "[262 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6. 유럽 질병예방통제센터 European Centre for Disease Prevention and Control,EcDC는\n",
    "#전 세계 국 가별 COVID-19 일일 신규 확진자 발생 보고 건수라고 하는 COVID-19 신규 확 진자 수 데이터셋을 공개하고 있다\n",
    "# (htps://www.ecdc.europa. eu/en/publications-datal download-todays-data-geographic-distribution-covid-19-cases-worldwide). \n",
    "# 이 데이처셋은 매일 업데이트되지만 2020년 1월 1일부터 2020년 9월 18일까지의 데이터가 포함된 데이터를 사용한다. \n",
    "#데이터를 정제하고 피보팅해 넓은 형태로 만든다.\n",
    "\n",
    "import pandas as pd\n",
    "# a) covid19_cases.csv 파일을 읽는다.\n",
    "covid19= pd.read_csv(\"data/covid19_cases.csv\")\n",
    "#print(covid19)\n",
    "\n",
    "# b) dateRep 열의 데이터와 pd.to_datetime() 함수를 사용해 date 열을 만든다.\n",
    "covid19['date'] = pd.to_datetime(covid19['dateRep'],format='%d/%m/%Y')\n",
    "print(covid19.dtypes)\n",
    "# c) date 열을 인덱스로 설정하고 인덱스를 기준으로 정렬한다.\n",
    "covid19.set_index('date',drop=False)\n",
    "\n",
    "# d) united_states_of_America와 United_Kingdom의 모든 항목을 각각 USA와 UK로 바 꾼다. \n",
    "#힌트: replace() 메서드를 Dcovid19[atafFrame 전체에 대해 실행한다.\n",
    "covid19['countriesAndTerritories']= covid19['countriesAndTerritories'].replace(\"United_States_of_America\",\"USA\")\n",
    "covid19['countriesAndTerritories']=covid19['countriesAndTerritories'].replace(\"United_Kingdom\",\"UK\")\n",
    "covid19['countriesAndTerritories'][64]\n",
    "\n",
    "# e) countriesAndTerritories 열을 사용해 정제한 COVID-19 신규 확진자 수 데이터 를 아르헨티나Argentina, 브라질Breal, \n",
    "#중국china, 콜롬비아Colormbia, 인도mda, 이탈리 orialy, 멕시코Mexco, 페루Per, 러시이 PusSi., 스페인5palr, 터키 Turker, \n",
    "#영국 UK', 미국 USA으로 필터링한다.\n",
    "convid_u= covid19[covid19['countriesAndTerritories'].isin(['Argentina', 'Brazil', 'China', 'Colombia', 'India', 'Italy', \n",
    "        'Mexico', 'Peru', 'Russia', 'Spain', 'Turkey', 'UK', 'USA'])]\n",
    "print(convid_u)\n",
    "\n",
    "\n",
    "# f) 날짜가 인덱스되고 국가명을 열로 하고, 값은 (cases 열에) 신규 확진자 수가 되도 록 데이터를 피보팅한다. NaN은 0.으로 채워야 한다.\n",
    "final_covid = convid_u.reset_index().pivot(index='date', columns='countriesAndTerritories', values='cases').fillna(0)\n",
    "print(final_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34b68a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Afghanistan  Albania  Algeria  Andorra  Angola  Anguilla  \\\n",
      "index                                                             \n",
      "cases        38919    12073    49413     1564    3789         3   \n",
      "\n",
      "       Antigua_and_Barbuda  Argentina  Armenia  Aruba  ...  \\\n",
      "index                                                  ...   \n",
      "cases                   95     601700    46910   3460  ...   \n",
      "\n",
      "       United_Republic_of_Tanzania  United_States_Virgin_Islands  Uruguay  \\\n",
      "index                                                                       \n",
      "cases                          509                          1242     1890   \n",
      "\n",
      "       Uzbekistan  Venezuela  Vietnam  Western_Sahara  Yemen  Zambia  Zimbabwe  \n",
      "index                                                                           \n",
      "cases       50253      65174     1068             766   2024   14022      7647  \n",
      "\n",
      "[1 rows x 210 columns]\n",
      "index\n",
      "cases    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>6724667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>5308014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>4495183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>1091186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>756412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>750471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>688954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South_Africa</th>\n",
       "      <td>657627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>640040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>442827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>428696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran</th>\n",
       "      <td>416198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>345805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saudi_Arabia</th>\n",
       "      <td>328720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>305031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>299810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>294932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index           cases\n",
       "USA           6724667\n",
       "India         5308014\n",
       "Brazil        4495183\n",
       "Russia        1091186\n",
       "Peru           756412\n",
       "Colombia       750471\n",
       "Mexico         688954\n",
       "South_Africa   657627\n",
       "Spain          640040\n",
       "Argentina      601700\n",
       "Chile          442827\n",
       "France         428696\n",
       "Iran           416198\n",
       "UK             385936\n",
       "Bangladesh     345805\n",
       "Saudi_Arabia   328720\n",
       "Iraq           311690\n",
       "Pakistan       305031\n",
       "Turkey         299810\n",
       "Italy          294932"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. 국가별 전체 신규 확진자 수를 효율적으로 계산하여면 4장에서 \n",
    "# 배울 집계 기술이 필요하므로 covid19_cases.csv 파일의 ECDC데이터를 집계해\n",
    "# covid19_total_cases.csv 파일에 저장해 뒀다. 이 파일에 국가별 전체 신규 확진자 수가 포함돼 있다. \n",
    "# 이 데이터를 사용해 COVID-19 전체 신규 확진자 수가 가장 많은 상위 20개 국가를 찾는다. \n",
    "#(힌트 : CSV파일을 읽을때 index_col ='cases'를 사용하고, 국가를 분리하기전에 데이터를 전치하는 것이 도움된다.)\n",
    "\n",
    "covid19_total= pd.read_csv(\"data/covid19_total_cases.csv\",index_col='index')\n",
    "print(covid19_total)\n",
    "covid19_total2=covid19_total.T \n",
    "print(covid19_total2.dtypes)\n",
    "covid19_total2.nlargest(20,'cases')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
